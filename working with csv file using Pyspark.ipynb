{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b720eaa7",
   "metadata": {},
   "source": [
    "<h1 align='center'>Lets Start working with CSV file in Pyspark</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c537a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48f9b2",
   "metadata": {},
   "source": [
    "* Let start try to read the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98640ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.read.csv(\"data/annual1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6c569",
   "metadata": {},
   "source": [
    "* using printSchema we can check the dataframe Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3174a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c3a255",
   "metadata": {},
   "source": [
    "* from above example reads the data into DataFrame columns \"_c0\" for the first column and \"_c1\" for the second and so on.\n",
    "* In input file and have header then you have to explicitly need to mention True as we did in the below code script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9262491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_header = spark.read.csv(\"data/annual1.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bcef8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Industry_aggregation_NZSIOC: string (nullable = true)\n",
      " |-- Industry_code_NZSIOC: string (nullable = true)\n",
      " |-- Industry_name_NZSIOC: string (nullable = true)\n",
      " |-- Units: string (nullable = true)\n",
      " |-- Variable_code: string (nullable = true)\n",
      " |-- Variable_name: string (nullable = true)\n",
      " |-- Variable_category: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      " |-- Industry_code_ANZSIC06: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv_header.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4948eaf0",
   "metadata": {},
   "source": [
    "* Read multiple CSV file in Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a05d8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path = [\"C:/Users/RajanSahu/Desktop/study/Pyspark/data/annual1.csv\", \"C:/Users/RajanSahu/Desktop/study/Pyspark/data/annual2.csv\"]\n",
    "\n",
    "df_csv_multiple = spark.read.csv(final_path,sep=',',\n",
    "                       inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3820ce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Industry_aggregation_NZSIOC: string (nullable = true)\n",
      " |-- Industry_code_NZSIOC: string (nullable = true)\n",
      " |-- Industry_name_NZSIOC: string (nullable = true)\n",
      " |-- Units: string (nullable = true)\n",
      " |-- Variable_code: string (nullable = true)\n",
      " |-- Variable_name: string (nullable = true)\n",
      " |-- Variable_category: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      " |-- Industry_code_ANZSIC06: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv_multiple.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed3e55",
   "metadata": {},
   "source": [
    "* Read all the file of the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b342e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"C:/Users/RajanSahu/Desktop/study/Pyspark/data/*.csv\"\n",
    "df_csv_directory =spark.read.csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce4f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_directory.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2998bd",
   "metadata": {},
   "source": [
    "* Lets see about Options while reading the data from CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7053a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_options_delimeter = spark.read.options(delimiter=',') \\\n",
    "  .csv(\"C:/Users/RajanSahu/Desktop/study/Pyspark/data/annual1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac7d8748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41702"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_options_delimeter.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3c9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option_delimeter = spark.read.option(\"delimiter\",',') \\\n",
    "  .csv(\"C:/Users/RajanSahu/Desktop/study/Pyspark/data/annual1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0f8899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41702"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_option_delimeter.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4356c94c",
   "metadata": {},
   "source": [
    "* Delimeter is used to specified the csv file delimeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a1fc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba59ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_options_inferschema = spark.read.options(inferSchema='True',delimiter=',') \\\n",
    "                              .csv(\"C:/Users/RajanSahu/Desktop/study/Pyspark/data/annual1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd47f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option_inferschema = spark.read.option(\"inferSchema\",True) \\\n",
    "                            .option(\"delimiter\",\",\") \\\n",
    "                            .csv(\"C:/Users/RajanSahu/Desktop/study/Pyspark/data/annual1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86715201",
   "metadata": {},
   "source": [
    "* default value of InferSchema is False\n",
    "* When you set InferSchema is True then it automatically infer the schema if the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3852ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_option_inferschema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aaa1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_options_inferschema_header = spark.read.options(header=True, inferSchema=True, delimiter=',') \\\n",
    "                        .csv(\"C:/Users/RajanSahu/Desktop/study/Pyspark/data/annual1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492dec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option_inferschema_header = spark.read.option(\"header\",True) \\\n",
    "                        .option(\"inferSchema\",True) \\\n",
    "                        .option(\"delimiter\",',')  \\\n",
    "                        .csv(\"C:/Users/RajanSahu/Desktop/study/Pyspark/data/annual1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74c16b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Industry_aggregation_NZSIOC: string (nullable = true)\n",
      " |-- Industry_code_NZSIOC: string (nullable = true)\n",
      " |-- Industry_name_NZSIOC: string (nullable = true)\n",
      " |-- Units: string (nullable = true)\n",
      " |-- Variable_code: string (nullable = true)\n",
      " |-- Variable_name: string (nullable = true)\n",
      " |-- Variable_category: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      " |-- Industry_code_ANZSIC06: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_option_inferschema_header.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b81cffd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3064a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------+\n",
      "|    Value|Industry_code_NZSIOC|    Value|\n",
      "+---------+--------------------+---------+\n",
      "|   69,127|               99999|   69,127|\n",
      "|  103,330|               99999|  103,330|\n",
      "|2,512,677|               99999|2,512,677|\n",
      "|  730,587|               99999|  730,587|\n",
      "|  591,351|               99999|  591,351|\n",
      "|1,190,739|               99999|1,190,739|\n",
      "|2,512,677|               99999|2,512,677|\n",
      "|  813,949|               99999|  813,949|\n",
      "|  933,093|               99999|  933,093|\n",
      "|  765,635|               99999|  765,635|\n",
      "|  400,900|               99999|  400,900|\n",
      "|   54,700|               99999|   54,700|\n",
      "|       78|               99999|       78|\n",
      "|       71|               99999|       71|\n",
      "|       13|               99999|       13|\n",
      "|        4|               99999|        4|\n",
      "|       32|               99999|       32|\n",
      "|   48,731|                  AA|   48,731|\n",
      "|   45,650|                  AA|   45,650|\n",
      "|      640|                  AA|      640|\n",
      "+---------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_option_inferschema_header.select(\"Value\",\"Industry_code_NZSIOC\", \"Value\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57949547",
   "metadata": {},
   "source": [
    "* As you can see from the coloums all are not string It is Integer let use feature of spark and change it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e614615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "structureSchema = StructType([ \\\n",
    "    StructField(\"Year\",IntegerType(),True), \\\n",
    "    StructField(\"Industry_aggregation_NZSIOC\",StringType(),True), \\\n",
    "    StructField(\"Industry_code_NZSIOC\",IntegerType(),True), \\\n",
    "    StructField(\"Industry_name_NZSIOC\",StringType(),True), \\\n",
    "    StructField(\"Units\", StringType(), True), \\\n",
    "    StructField(\"Variable_code\", StringType(), True), \\\n",
    "    StructField(\"Variable_name\", StringType(), True), \\\n",
    "    StructField(\"Variable_category\", StringType(), True), \\\n",
    "    StructField(\"Value\", IntegerType(), True), \\\n",
    "    StructField(\"Industry_code_ANZSIC06\", StringType(), True) \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ace4bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_options = spark.read.schema(structureSchema) \\\n",
    "                        .option(\"header\",True) \\\n",
    "                        .option(\"inferSchema\",True) \\\n",
    "                        .option(\"delimiter\",',') \\\n",
    "                        .csv(\"C:/Users/RajanSahu/Desktop/study/Pyspark/data/annual1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab990af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Industry_aggregation_NZSIOC: string (nullable = true)\n",
      " |-- Industry_code_NZSIOC: integer (nullable = true)\n",
      " |-- Industry_name_NZSIOC: string (nullable = true)\n",
      " |-- Units: string (nullable = true)\n",
      " |-- Variable_code: string (nullable = true)\n",
      " |-- Variable_name: string (nullable = true)\n",
      " |-- Variable_category: string (nullable = true)\n",
      " |-- Value: integer (nullable = true)\n",
      " |-- Industry_code_ANZSIC06: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_options.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd46aded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|Industry_code_ANZSIC06|\n",
      "+----------------------+\n",
      "|  ANZSIC06 division...|\n",
      "|  ANZSIC06 division...|\n",
      "+----------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_options.select(\"Industry_code_ANZSIC06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d681e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option1 = spark.read.options(schema=structureSchema,header=True, inferSchema=True, delimiter=',') \\\n",
    "                        .csv(\"C:/Users/RajanSahu/Desktop/study/Pyspark/data/annual1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3282f8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Industry_aggregation_NZSIOC: string (nullable = true)\n",
      " |-- Industry_code_NZSIOC: string (nullable = true)\n",
      " |-- Industry_name_NZSIOC: string (nullable = true)\n",
      " |-- Units: string (nullable = true)\n",
      " |-- Variable_code: string (nullable = true)\n",
      " |-- Variable_name: string (nullable = true)\n",
      " |-- Variable_category: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      " |-- Industry_code_ANZSIC06: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_option1.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
